{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "\n",
    "- [1 - 背景](#1)\n",
    "- [2 - 理解需求价格弹性](#2)\n",
    "- [3 - 导入库](#3)\n",
    "- [4 - 探索性数据分析](#4)\n",
    "- [5 - 合并数据](#5)\n",
    "     - [5.1 - 探索合并数据](#5.1)\n",
    "     - [5.2 - 通过可视化揭示数据侧面](#5.2)\n",
    "     - [5.3 - 合并数据的探索性分析](#5.3)\n",
    "- [6 - 建模](#6)\n",
    "- [7 - 在所有产品上应用模型](#7)\n",
    "     - [7.1 - 最大利润的最优价格](#7.1)\n",
    "     - [7.2 - 所有商品的最大利润最优价格](#7.2)\n",
    "- [8 - 结论](#8)\n",
    "\n",
    "<a name='1'></a>\n",
    "### 基于需求价格弹性的价格优化\n",
    "\n",
    "**价格优化** 是公司使用分析来了解客户如何响应其产品或服务的价格(购买模式),并用于确定在线或线下商店应设定什么价格,以便公司能够满足其大部分目标。一些目标可能是:\n",
    "\n",
    "获得更多利润、更多收入等\n",
    "实现这一目标的数据可能多种多样,可以是调查数据、以前的销售数据等\n",
    "\n",
    "**使用案例** 零售、航空、银行、酒店、本地\n",
    "\n",
    "**谁需要定价?** 分析师或企业主\n",
    "\n",
    "**产品定价策略?**\n",
    "\n",
    "- 成本加成定价(最简单的形式):假设你以$\\$100$的价格销售某物,并决定要获得$\\$10$的利润,那么你的售价是$\\$110$。你根据总采购价格、维护价格、生产价格来决定,即无论成本是多少,你都会在其上添加一个百分比。\n",
    "- 基于竞争的定价:根据竞争对手的定价,你决定可以降低一定的百分比。\n",
    "- 基于感知价值的定价:了解特定产品对客户有什么价值,他们如何感知这些产品并相应地定价,例如许多奢侈品,其价格不是基于材料成本、生产成本、分销成本或竞争对手的定价。只是对客户而言具有更高的价值,因此价格更高。\n",
    "- 基于需求的定价:根据产品的需求,你可以决定定价,即如果需求高,你可以提高价格,如果需求低,你可以进行一些促销或折扣或降低价格。\n",
    "- 价格弹性\n",
    "\n",
    "**我应该如何给产品定价** 取决于许多问题和最终目标,我是否想增加销售数量,即增加你销售的商品数量,利润和收入不在你脑海中的首要位置,还是你想要更多的客流量进入你的商店/网站,即每当亚马逊想要打入市场时就会大幅折扣,或者你想增加更多的收入和更多的利润(这是我们感兴趣的)。\n",
    "\n",
    "**如何使用我拥有的销售数据为产品定价** \n",
    "- 销售数据\n",
    "- 属性 - 价格弹性:衡量商品需求量或供应量对价格变化的响应程度。它可以是,\n",
    "  - 弹性产品 - 消费者对价格变化有响应(模式基于价格变化)这是我们关注的重点。\n",
    "  - 非弹性产品 - 消费者对价格变化没有响应(销售不太受价格变化影响,即奢侈品。)\n",
    "\n",
    "<a name='2'></a>\n",
    "### 价格弹性\n",
    "\n",
    "需求价格弹性(PED)是一种衡量指标,用于显示当其他条件不变时,商品或服务的需求量对价格变化的响应程度,即需求与价格之间的关系。即对某物的有效需求随着价格变化而变化。它给出了价格增加1%时数量的百分比变化\n",
    "数学上\n",
    "$$ e = \\frac{\\Delta Q}{\\Delta P}$$\n",
    "\n",
    "我们将查看销售汉堡的咖啡馆的销售情况,咖啡馆老板想知道为其商品设定的最优价格,以获得最大利润。注意:如果价格高,销售会减少,如果价格低,销售会增加,因此总利润会减少。所以这里的任务是找到一个最佳点,能给我们最大的利润。因此我们试图找到数量和价格之间的线性关系,因此在这种情况下使用线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "### 加载库和数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在同一单元格中获取多个输出\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# 忽略所有警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "# 显示数据框的所有行和列而不是截断版本\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "sold = pd.read_csv(\"C:\\\\Python code\\\\Cafe analysis\\\\Cafe+-+Sell+Meta+Data.csv\")\n",
    "transaction = pd.read_csv(\"C:\\\\Python code\\\\Cafe analysis\\\\Cafe+-+Transaction+-+Store.csv\")\n",
    "date_info = pd.read_csv(\"C:\\\\Python code\\\\Cafe analysis\\\\Cafe+-+DateInfo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "### 探索性数据分析\n",
    "\n",
    "**销售数据集:**\n",
    "\n",
    "SELL_ID: 分类变量,产品中包含的商品组合的标识符。\n",
    "\n",
    "SELL_CATEGORY: \"0\"标识单个产品;\"2\"类别标识组合产品。\n",
    "\n",
    "ITEM_ID: 分类变量,产品中包含的商品的标识符,与item_name为一对一关系。\n",
    "\n",
    "ITEM_NAME: 分类变量,标识商品的名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 销售数据集的探索性数据分析\n",
    "sold.head()\n",
    "sold.dtypes\n",
    "sold.describe()\n",
    "sold.describe(include=[\"O\"])\n",
    "sold[sold.isnull().any(axis=1)]\n",
    "sns.pairplot(sold)\n",
    "\n",
    "# 获取每行的唯一销售ID\n",
    "pd.concat([sold.SELL_ID, pd.get_dummies(sold.ITEM_NAME)], axis=1)\n",
    "pd.concat([sold.SELL_ID, pd.get_dummies(sold.ITEM_NAME)], axis=1).groupby(sold.SELL_ID).sum()#seaborn函数，对角线为直方图，其余为散点图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**交易数据集:**\n",
    "\n",
    "重要说明:假设该产品在当天的价格不会变化。\n",
    "\n",
    "详细信息:\n",
    "CALENDAR_DATE: 日期/时间变量,时间始终设置为00:00 AM。\n",
    "\n",
    "PRICE: 数值变量,与SELL_ID标识的产品价格相关联。\n",
    "\n",
    "QUANTITY: 数值变量,与SELL_ID标识的产品的销售数量相关联。\n",
    "\n",
    "SELL_ID: 分类变量,销售产品的标识符。\n",
    "\n",
    "SELL_CATEGORY: 分类变量,销售产品的类别。\n",
    "\n",
    "- 可以很容易地看出价格分布是双峰分布,因为它在两个点达到峰值。\n",
    "- 它可能是许多分布的组合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交易数据集的探索性数据分析\n",
    "transaction.head()\n",
    "transaction.describe()\n",
    "transaction.describe(include=['O'])\n",
    "transaction[transaction.isnull().any(axis=1)]\n",
    "plt.hist(transaction.PRICE)\n",
    "sns.pairplot(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日期信息数据集的探索性数据分析\n",
    "date_info.head()\n",
    "date_info.describe()\n",
    "date_info.describe(include=['O'])\n",
    "date_info.dtypes\n",
    "date_info[date_info.isnull().any(axis=1)]\n",
    "\n",
    "# 替换缺失值\n",
    "date_info['HOLIDAY'] = date_info['HOLIDAY'].fillna(\"No Holiday\")\n",
    "date_info\n",
    "sns.pairplot(date_info)\n",
    "\n",
    "# 进一步的探索性数据分析\n",
    "np.unique(date_info['HOLIDAY'])\n",
    "date_info['HOLIDAY'].value_counts()\n",
    "date_info['CALENDAR_DATE'].min()\n",
    "date_info['CALENDAR_DATE'].max()\n",
    "date_info.shape\n",
    "date_info[date_info.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name ='5'></a>\n",
    "### 合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并并删除不必要的列\n",
    "merge_data1 = pd.merge(sold.drop(['ITEM_ID'], axis=1), transaction.drop(['SELL_CATEGORY'], axis=1), on= 'SELL_ID')\n",
    "merge_data1.head(20)\n",
    "\n",
    "# 使 merge_data1 在所有返回特征的组合上具有唯一性\n",
    "unique_merge_data1 = merge_data1.groupby(['SELL_ID', 'SELL_CATEGORY', 'ITEM_NAME', 'CALENDAR_DATE', 'PRICE']).QUANTITY.sum()\n",
    "unique_merge_data1.head(20)\n",
    "merge_data1.shape\n",
    "unique_merge_data1.shape\n",
    "intermediate_data = unique_merge_data1.reset_index()\n",
    "intermediate_data.head()\n",
    "intermediate_data['CALENDAR_DATE'].min()\n",
    "intermediate_data['CALENDAR_DATE'].max()\n",
    "\n",
    "# 整合日期信息数据\n",
    "combined_data = pd.merge(intermediate_data, date_info, on= 'CALENDAR_DATE')\n",
    "combined_data.head()\n",
    "combined_data.shape\n",
    "combined_data[combined_data.isnull().any(axis=1)]\n",
    "np.unique(combined_data.HOLIDAY)\n",
    "np.unique(combined_data.IS_WEEKEND)\n",
    "np.unique(combined_data.IS_SCHOOLBREAK)\n",
    "\n",
    "#这些属性在我们的销售中非常重要，但与价格无关。例如，如果遇到节假日，销售量会增加；\n",
    "# 如果遇到学校假期且周末，销售量也会增加。但我们不希望看到这种影响，因为我们只对价格的影响感兴趣。\n",
    "# 数据集中将移除所有与价格无关的销售影响因素。\n",
    "bau_data = combined_data[(combined_data['HOLIDAY']=='No Holiday') & (combined_data['IS_SCHOOLBREAK']==0) & \n",
    "                         (combined_data['IS_WEEKEND']==0)]\n",
    "bau_data.head()\n",
    "bau_data.shape\n",
    "np.unique(bau_data.HOLIDAY)\n",
    "np.unique(bau_data.IS_WEEKEND)\n",
    "np.unique(bau_data.IS_SCHOOLBREAK)\n",
    "bau_data[bau_data['IS_WEEKEND']==1]\n",
    "bau_data[bau_data['HOLIDAY']!='No Holiday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5.1'></a>\n",
    "#### 组合数据的探索性数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 物品名称\n",
    "plt.hist(bau_data.ITEM_NAME)\n",
    "# 价格\n",
    "plt.hist(bau_data.PRICE)\n",
    "# 组合数据集中的价格与数量\n",
    "plt.scatter(combined_data.PRICE, combined_data.QUANTITY)\n",
    "# 在bau数据集中，这不包含特殊日期\n",
    "plt.scatter(bau_data.PRICE, bau_data.QUANTITY)\n",
    "# 组合数据的配对图\n",
    "sns.pairplot(combined_data[['PRICE','QUANTITY','ITEM_NAME']], hue = 'ITEM_NAME', plot_kws={'alpha':0.1})\n",
    "# bau数据的配对图\n",
    "sns.pairplot(bau_data[['PRICE','QUANTITY','ITEM_NAME']], hue = 'ITEM_NAME', plot_kws={'alpha':0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "价格密度图呈现双峰形态。从图表中可以看出，对于所有数量而言，随着价格的提高，销售量呈下降趋势。尽管可乐在该视图中被隐藏了。我们可以继续计算这些产品的价格弹性。\n",
    "\n",
    "<a name='5.2'></a>\n",
    "#### 用可视化手段揭示数据的各个层面\n",
    "\n",
    "从散点图中可以明显看出，一定存在不同类型的小吃堡在销售。现在让我们看看当用SELL_ID进行区分时的相同分布情况，SELL_ID表示该小吃堡是否为套餐的一部分，因此必须单独处理。\n",
    "\n",
    "* 因此，SELL_ID 也是导致这些不同群体和不同行为的因素之一，所以按每个 ITEM_NAME 对数据进行拆分是合理的。因为如帖子中所示，我们无法用具有两种分布的数据来拟合模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汉堡的各个部分\n",
    "burger = combined_data[combined_data['ITEM_NAME'] == 'BURGER']\n",
    "burger.head()\n",
    "burger.shape \n",
    "burger.describe()\n",
    "sns.scatterplot(x=burger.PRICE, y=burger.QUANTITY)\n",
    "\n",
    "# alpha用于设置透明度，图例可能需要完整显示以查看各种SELL_ID和组合\n",
    "burger = combined_data[combined_data['ITEM_NAME'] == 'BURGER']\n",
    "sns.scatterplot(data = burger, x = burger.PRICE, y = burger.QUANTITY , hue = 'SELL_ID', legend=False, alpha = 0.1)\n",
    "\n",
    "np.unique(combined_data.SELL_ID)\n",
    "np.unique(combined_data.SELL_CATEGORY)\n",
    "\n",
    "# 为特定销售ID创建包含汉堡的组合产品的视觉效果\n",
    "burger_1070 = combined_data[(combined_data['ITEM_NAME'] == 'BURGER') & (combined_data['SELL_ID'] == 1070)]\n",
    "burger_1070.head()\n",
    "burger_1070.describe()\n",
    "sns.scatterplot(data = burger_1070, x = burger_1070.PRICE, y = burger_1070.QUANTITY, alpha = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "### 建模\n",
    "\n",
    "* 由于R平方值较低，模型与数据的拟合效果不佳，存在较大差异。让我们在移除节假日、周末和学校假期后的数据中进行观察。\n",
    "\n",
    "* 图表中部分右侧区域的缺失对应特殊日子和节假日。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用组合数据\n",
    "burger_model = ols(\"QUANTITY ~ PRICE\", data=burger_1070).fit() \n",
    "print(burger_model.summary())\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "fig = sm.graphics.plot_partregress_grid(burger_model, fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按项目名称“汉堡”对bau数据集进行子集划分\n",
    "burger = bau_data[bau_data['ITEM_NAME'] == 'BURGER']\n",
    "burger.head()\n",
    "burger.shape\n",
    "burger.describe()\n",
    "sns.scatterplot(x = burger.PRICE, y = burger.QUANTITY)\n",
    "\n",
    "burger = bau_data[bau_data['ITEM_NAME'] == 'BURGER']\n",
    "sns.scatterplot(data=burger, x =burger.PRICE, y= burger.QUANTITY, hue= 'SELL_ID', legend=False, alpha=0.1)\n",
    "\n",
    "# 唯一销售ID，该BAU数据包含所有销售ID\n",
    "np.unique(bau_data.SELL_ID)\n",
    "np.unique(bau_data.SELL_CATEGORY)\n",
    "\n",
    "# 子集销售编号1070汉堡及套餐\n",
    "burger_1070 = bau_data[(bau_data['ITEM_NAME'] == 'BURGER') & (bau_data['SELL_ID'] == 1070)]\n",
    "burger_1070.head()\n",
    "burger_1070.describe()\n",
    "sns.scatterplot(data= burger_1070, x =burger_1070.PRICE, y= burger_1070.QUANTITY, alpha=0.1)\n",
    "\n",
    "# 在新数据上拟合OLS模型\n",
    "burger_model = ols('QUANTITY ~ PRICE', data=burger_1070).fit()\n",
    "print(burger_model.summary())\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "fig = sm.graphics.plot_partregress_grid(burger_model, fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 由于R平方值的增加，变异程度有所降低，模型对趋势的捕捉也更好。然而，我们可以观察到两条独立的趋势线。\n",
    "\n",
    "* 我们将再次探索数据，看看数据中还有哪些其他因素可以用来进一步优化我们的模型。\n",
    "\n",
    "* 图表更加清晰，只包含一个组别。\n",
    "\n",
    "* 趋势明显，线条清晰，仅有小幅波动。我们可以有把握地说，在这家特定的咖啡馆中，对于售价ID为1070的汉堡，价格系数约为-5.3513，因此价格弹性为-5。\n",
    "\n",
    "* 现在我们已经弄清楚如何为售价ID为1070的特定汉堡计算价格弹性，接下来我们将将其扩展到其他商品。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再读数据\n",
    "bau_data.head()\n",
    "\n",
    "# 不确定“outdoor”是什么意思，也把“outdoor”过滤掉\n",
    "bau2_data = combined_data[(combined_data['HOLIDAY'] == 'No Holiday') & (combined_data['IS_SCHOOLBREAK'] ==0) & \n",
    "                          (combined_data['IS_WEEKEND'] == 1) & (combined_data['IS_OUTDOOR'] ==1)]\n",
    "\n",
    "# 使用汉堡数据集创建组合\n",
    "burger_1070 = bau2_data[(bau2_data['ITEM_NAME'] == 'BURGER') & (bau2_data['SELL_ID'] == 1070)]\n",
    "burger_1070.head()\n",
    "burger_1070.describe()\n",
    "sns.scatterplot(data= burger_1070, x = burger_1070.PRICE, y= burger_1070.QUANTITY, alpha= 0.1)\n",
    "\n",
    "# 使用这些数据创建模型\n",
    "burger_model = ols(\"QUANTITY ~ PRICE\", data= burger_1070).fit()\n",
    "print(burger_model.summary())\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig = sm.graphics.plot_ccpr(burger_model, \"PRICE\")\n",
    "\n",
    "# 让我们从另一个角度看待同一个模型\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig = sm.graphics.plot_regress_exog(burger_model, \"PRICE\", fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "### 将模型应用于所有产品\n",
    "\n",
    "* 这个图表看起来还不错，因为它没有显得杂乱无章。\n",
    "\n",
    "* 再次看R平方值仍然很低，尽管它捕捉到了下降趋势，但我们仍然看到很多变异性。\n",
    "\n",
    "* 散点图不是很清晰，存在两个不同的分组，让我们尝试拟合一个模型，我们看到的R平方值比汉堡模型更好，但仍然较低，尽管捕捉到了下降趋势。\n",
    "\n",
    "* 看起来有两个不同的分组，存在一些价格差距。\n",
    "\n",
    "* 价格的系数为-5，这意味着价格弹性为-5。\n",
    "\n",
    "* 与之前的饮料（可乐和咖啡）类似。\n",
    "\n",
    "* 看起来R平方值比汉堡更好，价格弹性为-2.5，然而与其他所有商品存在的相同问题依然存在。\n",
    "\n",
    "* 我们将使用更简洁的数据函数，并创建一个通用函数，该函数以数据为输入并产生最佳结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只是核对一下卖品ID为2051的汉堡和套餐\n",
    "burger_2051 = combined_data[(combined_data['ITEM_NAME'] == 'BURGER') & (combined_data['SELL_ID'] == 2051)]\n",
    "burger_2051.head()\n",
    "burger_2051.describe()\n",
    "sns.scatterplot(data= burger_2051, x = burger_2051.PRICE, y= burger_2051.QUANTITY, alpha=0.1)\n",
    "\n",
    "burger_model = ols('QUANTITY ~ PRICE', data=burger_2051).fit()\n",
    "print(burger_model.summary())\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "fig = sm.graphics.plot_partregress_grid(burger_model, fig=fig)\n",
    "\n",
    "# look at coke\n",
    "coke = combined_data[combined_data['ITEM_NAME'] == 'COKE']\n",
    "coke.head()\n",
    "coke.shape\n",
    "coke.describe()\n",
    "sns.scatterplot(x = coke.PRICE, y= coke.QUANTITY, alpha=0.1)\n",
    "\n",
    "coke_model = ols(\"QUANTITY ~ PRICE\", data=coke).fit()\n",
    "print(coke_model.summary())\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig = sm.graphics.plot_partregress_grid(coke_model, fig=fig)\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig = sm.graphics.plot_regress_exog(coke_model, \"PRICE\", fig = fig)\n",
    "\n",
    "# Coffee\n",
    "coffee = combined_data[combined_data['ITEM_NAME'] == 'COFFEE'] \n",
    "coffee.head()\n",
    "coffee.shape\n",
    "coffee.describe()\n",
    "sns.scatterplot(x = coffee.PRICE, y = coffee.QUANTITY , alpha = 0.1)\n",
    "\n",
    "# 构建和拟合模型\n",
    "model = ols(\"QUANTITY ~ PRICE\", data=coffee).fit() \n",
    "print(model.summary())\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "fig = sm.graphics.plot_partregress_grid(model, fig=fig)\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, 'PRICE', fig=fig)\n",
    "\n",
    "# Lemonade柠檬水 \n",
    "Lemonade_df = combined_data[combined_data['ITEM_NAME'] == 'LEMONADE']\n",
    "Lemonade_df.head()\n",
    "Lemonade_df.shape\n",
    "Lemonade_df.describe()\n",
    "sns.scatterplot(x = Lemonade_df.PRICE, y = Lemonade_df.QUANTITY , alpha = 0.1)\n",
    "\n",
    "# fit model for lemonade\n",
    "model = ols(\"QUANTITY ~ PRICE\", data=Lemonade_df).fit()\n",
    "print(model.summary())\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "fig = sm.graphics.plot_partregress_grid(model, fig=fig)\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, 'PRICE', fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为所有项目查找弹性\n",
    "elasticities = {}\n",
    "\n",
    "# 获取价格弹性的通用函数\n",
    "def create_model_and_find_elasticity(data):\n",
    "    model = ols(\"QUANTITY ~ PRICE\", data).fit()\n",
    "    price_elasticity = model.params[1]\n",
    "    print('Price elasticiy of the product: ' + str(price_elasticity))\n",
    "    print(model.summary())\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    fig = sm.graphics.plot_partregress_grid(model, fig=fig)\n",
    "    return price_elasticity, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用函数\n",
    "price_elasticity, model_burger_1070 = create_model_and_find_elasticity(burger_1070)\n",
    "elasticities['burger_1070'] = price_elasticity\n",
    "\n",
    "# 2051及其他具有唯一销售ID的汉堡\n",
    "burger2051_data = bau2_data[(bau2_data['ITEM_NAME'] == \"BURGER\") & (bau2_data['SELL_ID'] == 2051)]\n",
    "elasticities['burger_2051'], model_burger_2051 = create_model_and_find_elasticity(burger2051_data)\n",
    "\n",
    "# 汉堡 2052\n",
    "burger2052_data = bau2_data[(bau2_data['ITEM_NAME'] == \"BURGER\") & (bau2_data['SELL_ID'] == 2052)]\n",
    "elasticities['burger_2052'], model_burger_2052 = create_model_and_find_elasticity(burger2052_data)\n",
    "\n",
    "# 汉堡 2053\n",
    "burger2053_data = bau2_data[(bau2_data['ITEM_NAME'] == \"BURGER\") & (bau2_data['SELL_ID'] == 2053)]\n",
    "elasticities['burger_2053'], model_burger_2053 = create_model_and_find_elasticity(burger2053_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coke data\n",
    "coke_data = bau2_data[bau2_data['ITEM_NAME'] == \"COKE\"]\n",
    "create_model_and_find_elasticity(coke_data)\n",
    "\n",
    "# 2053\n",
    "coke_data_2053 = bau2_data[(bau2_data['ITEM_NAME'] == \"COKE\") & (bau2_data['SELL_ID'] == 2053)]\n",
    "elasticities['coke_2053'], model_coke_2053 = create_model_and_find_elasticity(coke_data_2053)\n",
    "\n",
    "# 2051\n",
    "coke_data_2051 = bau2_data[(bau2_data['ITEM_NAME'] == \"COKE\") & (bau2_data['SELL_ID'] == 2051)]\n",
    "elasticities['coke_2051'], model_coke_2051 = create_model_and_find_elasticity(coke_data_2051)\n",
    "\n",
    "# Lemonade sell id 2052\n",
    "lemonade_data_2052 = bau2_data[(bau2_data['ITEM_NAME'] == \"LEMONADE\") & (bau2_data['SELL_ID'] == 2052)]\n",
    "elasticities['lemonade_2052'], model_lemonade_2052 = create_model_and_find_elasticity(lemonade_data_2052)\n",
    "\n",
    "# coffee with sell id 2053\n",
    "coffee_data_2053 = bau2_data[(bau2_data['ITEM_NAME'] == \"COFFEE\") & (bau2_data['SELL_ID'] == 2053)]\n",
    "elasticities['coffee_2053'], model_coffee_2053 = create_model_and_find_elasticity(coffee_data_2053)\n",
    "\n",
    "#以表格形式列出弹性\n",
    "elasticities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7.1'></a>\n",
    "#### 实现最大利润的最佳价格\n",
    "\n",
    "* 让我们以可乐为例，由于我们不知道可乐的购买价格，假设它略低于数据集中可乐的最低价格。\n",
    "\n",
    "\n",
    "让我们将可乐的购买价格设为9。现在我们希望设定可乐的售价以获得最大利润。此处PRICE表示 selling price（售价）。\n",
    "\n",
    "\n",
    "$$cokedata.PROFIT = (cokedata.PRICE - buyingpricecoke)* cokedata.QUANTITY$$\n",
    "\n",
    "\n",
    "* 让我们查看不同价格点的利润情况\n",
    "\n",
    "* 蓝色线表示价格与数量的关系，橙色线表示价格与利润的关系，我们需要在橙色曲线上找到最大值点\n",
    "\n",
    "* 让我们找出能获得最大利润的确切价格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coke_data.PRICE.min()\n",
    "coke_data.PRICE.max()\n",
    "\n",
    "buying_price_coke = 9\n",
    "\n",
    "# 随机的价格点，这些价格点是合理的\n",
    "start_price = 9.5\n",
    "end_price = 20\n",
    "\n",
    "# 测试数据集\n",
    "test = pd.DataFrame(columns= [ \"PRICE\", \"QUANTITY\"])\n",
    "\n",
    "# 价格以0.01为步长递增，面额也按此方式增加\n",
    "test[\"PRICE\"] = np.arange(start_price, end_price, 0.01)\n",
    "\n",
    "# 2051年的数量\n",
    "test[\"QUANTITY\"] = model_coke_2051.predict(test[\"PRICE\"])\n",
    "test \n",
    "\n",
    "# 利润\n",
    "test['PROFIT'] = (test[\"PRICE\"] - buying_price_coke) * test['QUANTITY'] \n",
    "test \n",
    "\n",
    "# 上面的表格形式\n",
    "plt.plot(test['PRICE'], test['QUANTITY'])\n",
    "plt.plot(test['PRICE'], test['PROFIT'])\n",
    "plt.show()\n",
    "\n",
    "# 确定实现最大利润的指数点\n",
    "ind = np.where(test['PROFIT'] == test['PROFIT'].max())[0][0]\n",
    "\n",
    "#行索引，这仅会在特定某一天产生利润。这将有助于在正常日进行一些库存规划，\n",
    "# 不考虑节假日等特殊日子。\n",
    "test.loc[[ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于最优价格的通用函数\n",
    "# 定义一个用于寻找最优价格的函数\n",
    "def find_optimal_price(data, model, buying_price):\n",
    "    start_price = data.PRICE.min() - 1              # start price\n",
    "    end_price = data.PRICE.min() + 10               # end price\n",
    "    test = pd.DataFrame(columns = [\"PRICE\", \"QUANTITY\"])  # 选择所需的列\n",
    "    test['PRICE'] = np.arange(start_price, end_price,0.01)\n",
    "    test['QUANTITY'] = model.predict(test['PRICE'])         # make predictions\n",
    "    test['PROFIT'] = (test[\"PRICE\"] - buying_price) * test[\"QUANTITY\"]\n",
    "    plt.plot(test['PRICE'],test['QUANTITY'])       # 绘制结果\n",
    "    plt.plot(test['PRICE'],test['PROFIT']) \n",
    "    plt.show()\n",
    "    ind = np.where(test['PROFIT'] == test['PROFIT'].max())[0][0]\n",
    "    values_at_max_profit = test.iloc[[ind]]\n",
    "    return values_at_max_profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7.2'></a>\n",
    "#### 计算所有产品的最优价格并以表格形式列出\n",
    "\n",
    "* 这款特定的1070汉堡的利润曲线和销量曲线没有交叉，因此单独销售时很可能能获得较高的利润。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据合并数据的价格和数量初始散点图，确定了最优价格，并将最低购买价格设为9。\n",
    "optimal_price = {}\n",
    "buying_price = 9\n",
    "\n",
    "optimal_price['burger_1070'] = find_optimal_price(burger_1070, model_burger_1070, buying_price)\n",
    "optimal_price\n",
    "optimal_price['burger_2051'] = find_optimal_price(burger2051_data, model_burger_2051, buying_price)\n",
    "optimal_price['burger_2052'] = find_optimal_price(burger2052_data, model_burger_2052, buying_price)\n",
    "optimal_price['burger_2053'] = find_optimal_price(burger2053_data, model_burger_2053, buying_price)\n",
    "optimal_price['coke_2051'] = find_optimal_price(coke_data_2051, model_coke_2051, buying_price)\n",
    "optimal_price['coke_2053'] = find_optimal_price(coke_data_2053, model_coke_2053, buying_price)\n",
    "optimal_price['lemonade_2052'] = find_optimal_price(lemonade_data_2052, model_lemonade_2052, buying_price)\n",
    "\n",
    "# 最优价格\n",
    "optimal_price\n",
    "\n",
    "# 初始价格\n",
    "coke_data_2051.PRICE.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "### 结论\n",
    "\n",
    "* 这里我们看到，最高价格为13.27时，而能实现最大利润的最优价格可能是19.15。这意味着咖啡馆在利润上存在亏损。但如果他们以19.15的价格出售，销量可能会下降，当然销售数量会减少，但利润会增加。\n",
    "\n",
    "* 这不是在正常日子的情况，或者像节假日、有活动进行的其他日子，这些日子会对顾客的购买模式产生各种影响，通常在这些日子消费量会增加，必须对此进行特殊处理。\n",
    "\n",
    "* 同样重要的是，要排除除价格以外可能影响顾客购买行为的任何外部因素，包括商品处于折扣状态的数据点。在这种情况下，没有商品处于折扣状态。\n",
    "\n",
    "* 现在我们已经为每种商品确定了这些新的价格点，一旦设定，就很重要持续监控这些商品的销售和利润。可以创建一个仪表板来监控这类问题并提升利润（增加利润）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
